{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### 1. **Importing Libraries and Initializing Spark Session**:\n"
      ],
      "metadata": {
        "id": "hLyUuTR-eDhu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyspark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9FkNkGDZeIY6",
        "outputId": "392fab09-b506-4c96-acbf-87bc06109289"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.5.1.tar.gz (317.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.0/317.0 MB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.5.1-py2.py3-none-any.whl size=317488491 sha256=aa9d36f1273d1de12a9e215b337a2cc853fa0f7a9d58a58773a46a3fdbd145dc\n",
            "  Stored in directory: /root/.cache/pip/wheels/80/1d/60/2c256ed38dddce2fdd93be545214a63e02fbd8d74fb0b7f3a6\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.5.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pyspark\n",
        "from pyspark.sql import SparkSession, Row\n",
        "from pyspark.sql.types import StructType, StructField, StringType, IntegerType\n",
        "from pyspark.sql.functions import *\n",
        "\n",
        "# Define schema and sample data\n",
        "columns = [\"language\", \"users_count\"]\n",
        "data = [(\"Java\", \"20000\"), (\"Python\", \"100000\"), (\"Scala\", \"3000\")]\n",
        "\n",
        "# Initialize Spark session\n",
        "spark = SparkSession.builder.appName('SparkByExamples.com').getOrCreate()"
      ],
      "metadata": {
        "id": "ovsioRFPeG4O"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "   - Imports necessary PySpark libraries.\n",
        "   - Initializes a Spark session with the application name 'SparkByExamples.com'.\n",
        "   - Defines the schema and sample data.\n"
      ],
      "metadata": {
        "id": "X0aCDLnSkIfV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. **Creating RDD from Sample Data**:\n"
      ],
      "metadata": {
        "id": "vq7WcRQdkJev"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create RDD from sample data\n",
        "rdd = spark.sparkContext.parallelize(data)"
      ],
      "metadata": {
        "id": "sTiYYndrkLXb"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Creates an RDD from the list of tuples.\n"
      ],
      "metadata": {
        "id": "s8ZbZU1rkOjn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. **Converting RDD to DataFrame Without Specifying Column Names**:\n"
      ],
      "metadata": {
        "id": "nrE6hS7FkP1L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert RDD to DataFrame without specifying column names\n",
        "dfFromRDD1 = rdd.toDF()\n",
        "dfFromRDD1.printSchema()\n",
        "dfFromRDD1.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Re0f5fHckRjw",
        "outputId": "91e2be19-5800-400e-e70f-380792619f50"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- _1: string (nullable = true)\n",
            " |-- _2: string (nullable = true)\n",
            "\n",
            "+------+------+\n",
            "|    _1|    _2|\n",
            "+------+------+\n",
            "|  Java| 20000|\n",
            "|Python|100000|\n",
            "| Scala|  3000|\n",
            "+------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Converts the RDD to a DataFrame without specifying column names.\n",
        "- Prints the schema and shows the DataFrame content.\n"
      ],
      "metadata": {
        "id": "NVg3OrX6kTDX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. **Converting RDD to DataFrame With Specified Column Names**:\n"
      ],
      "metadata": {
        "id": "oubLs79rkUzh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert RDD to DataFrame with specified column names\n",
        "dfFromRDD1 = rdd.toDF(columns)\n",
        "dfFromRDD1.printSchema()\n",
        "dfFromRDD1.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SpCLDl2akWtO",
        "outputId": "c14fc632-e2d1-47ca-8cbb-7d15d3e6e8ee"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- language: string (nullable = true)\n",
            " |-- users_count: string (nullable = true)\n",
            "\n",
            "+--------+-----------+\n",
            "|language|users_count|\n",
            "+--------+-----------+\n",
            "|    Java|      20000|\n",
            "|  Python|     100000|\n",
            "|   Scala|       3000|\n",
            "+--------+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Converts the RDD to a DataFrame with specified column names.\n",
        "- Prints the schema and shows the DataFrame content."
      ],
      "metadata": {
        "id": "OsghrswukYCq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5. **Creating DataFrame From RDD Using createDataFrame Method**:\n"
      ],
      "metadata": {
        "id": "k-nPZSQ4kZ3o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create DataFrame from RDD using createDataFrame method with specified column names\n",
        "dfFromRDD2 = spark.createDataFrame(rdd).toDF(*columns)\n",
        "dfFromRDD2.printSchema()\n",
        "dfFromRDD2.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0VfWoc1bkbMv",
        "outputId": "8ddf1181-b406-41d9-c0e3-5df68529d08a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- language: string (nullable = true)\n",
            " |-- users_count: string (nullable = true)\n",
            "\n",
            "+--------+-----------+\n",
            "|language|users_count|\n",
            "+--------+-----------+\n",
            "|    Java|      20000|\n",
            "|  Python|     100000|\n",
            "|   Scala|       3000|\n",
            "+--------+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "  - Uses the `createDataFrame` method to create a DataFrame from the RDD and specifies column names.\n",
        "  - Prints the schema and shows the DataFrame content.\n"
      ],
      "metadata": {
        "id": "j7iaOrdVkdN9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6. **Creating DataFrame Directly From List of Tuples**:\n"
      ],
      "metadata": {
        "id": "u1uYwkVFkehL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create DataFrame directly from list of tuples\n",
        "dfFromData2 = spark.createDataFrame(data).toDF(*columns)\n",
        "dfFromData2.printSchema()\n",
        "dfFromData2.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fVKN867Vkimk",
        "outputId": "2140d909-de37-41d6-bbe9-0dca6ee6e7d8"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- language: string (nullable = true)\n",
            " |-- users_count: string (nullable = true)\n",
            "\n",
            "+--------+-----------+\n",
            "|language|users_count|\n",
            "+--------+-----------+\n",
            "|    Java|      20000|\n",
            "|  Python|     100000|\n",
            "|   Scala|       3000|\n",
            "+--------+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Creates a DataFrame directly from the list of tuples and specifies column names.\n",
        "- Prints the schema and shows the DataFrame content.\n"
      ],
      "metadata": {
        "id": "WvQV0q69kkYO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7. **Creating DataFrame Using Row Objects**:\n"
      ],
      "metadata": {
        "id": "1LuUnwyDklka"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create DataFrame using Row objects\n",
        "rowData = map(lambda x: Row(*x), data)\n",
        "dfFromData3 = spark.createDataFrame(rowData, columns)\n",
        "dfFromData3.printSchema()\n",
        "dfFromData3.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YvMTEPR2knGj",
        "outputId": "8a2c54cc-af58-479d-8511-ed52b08c5707"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- language: string (nullable = true)\n",
            " |-- users_count: string (nullable = true)\n",
            "\n",
            "+--------+-----------+\n",
            "|language|users_count|\n",
            "+--------+-----------+\n",
            "|    Java|      20000|\n",
            "|  Python|     100000|\n",
            "|   Scala|       3000|\n",
            "+--------+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "  - Converts the list of tuples into a list of `Row` objects.\n",
        "  - Creates a DataFrame from the list of `Row` objects and specifies column names.\n",
        "  - Prints the schema and shows the DataFrame content."
      ],
      "metadata": {
        "id": "2QO6mm7tkop5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Key Points\n",
        "\n",
        "- **Creating DataFrame from RDD**: Demonstrates how to create a DataFrame from an RDD with and without specifying column names.\n",
        "- **Using createDataFrame Method**: Shows how to use the `createDataFrame` method to create a DataFrame from an RDD and specify column names.\n",
        "- **Creating DataFrame from List of Tuples**: Demonstrates creating a DataFrame directly from a list of tuples.\n",
        "- **Using Row Objects**: Shows how to create a DataFrame from a list of `Row` objects.\n"
      ],
      "metadata": {
        "id": "xL-K6bqid9Ov"
      }
    }
  ]
}