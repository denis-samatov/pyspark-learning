{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### 1. **Initializing Spark Session**:\n"
      ],
      "metadata": {
        "id": "Hx31sXLzbnI9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyspark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bKjROexFbso5",
        "outputId": "66a2a743-951d-4bb6-8ea6-43aa6666b0a9"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.5.1.tar.gz (317.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.0/317.0 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.5.1-py2.py3-none-any.whl size=317488491 sha256=5099c5a9fe1e9fb3f160fd5339d5a599b952720b9a231400665223f710d685c3\n",
            "  Stored in directory: /root/.cache/pip/wheels/80/1d/60/2c256ed38dddce2fdd93be545214a63e02fbd8d74fb0b7f3a6\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.5.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.types import StructField, StructType, StringType, MapType\n",
        "from pyspark.sql.functions import explode, map_keys, col\n",
        "\n",
        "spark = SparkSession.builder.appName('SparkByExamples.com').getOrCreate()"
      ],
      "metadata": {
        "id": "jzAFim_HbrSe"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Imports necessary PySpark libraries.\n",
        "- Initializes a Spark session with the application name 'SparkByExamples.com'.\n"
      ],
      "metadata": {
        "id": "CDce_hFjbv-3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. **Defining Sample Data**:\n"
      ],
      "metadata": {
        "id": "LeCH0JxubxgU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataDictionary = [\n",
        "    ('James', {'hair': 'black', 'eye': 'brown'}),\n",
        "    ('Michael', {'hair': 'brown', 'eye': None}),\n",
        "    ('Robert', {'hair': 'red', 'eye': 'black'}),\n",
        "    ('Washington', {'hair': 'grey', 'eye': 'grey'}),\n",
        "    ('Jefferson', {'hair': 'brown', 'eye': ''})\n",
        "]"
      ],
      "metadata": {
        "id": "lC3exfb_b0Eg"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "   - Defines sample data with a dictionary column.\n"
      ],
      "metadata": {
        "id": "9edPGovPb2cd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. **Creating DataFrame with Inferred Schema**:\n"
      ],
      "metadata": {
        "id": "6gkmwKeAb3gw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = spark.createDataFrame(data=dataDictionary, schema=['name', 'properties'])\n",
        "df.printSchema()\n",
        "df.show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fcuefG95b5U-",
        "outputId": "154bab9b-96e8-4d11-f054-475daacde011"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- name: string (nullable = true)\n",
            " |-- properties: map (nullable = true)\n",
            " |    |-- key: string\n",
            " |    |-- value: string (valueContainsNull = true)\n",
            "\n",
            "+----------+-----------------------------+\n",
            "|name      |properties                   |\n",
            "+----------+-----------------------------+\n",
            "|James     |{eye -> brown, hair -> black}|\n",
            "|Michael   |{eye -> NULL, hair -> brown} |\n",
            "|Robert    |{eye -> black, hair -> red}  |\n",
            "|Washington|{eye -> grey, hair -> grey}  |\n",
            "|Jefferson |{eye -> , hair -> brown}     |\n",
            "+----------+-----------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "   - Creates a DataFrame with the inferred schema.\n",
        "   - Prints the schema and shows the DataFrame content.\n"
      ],
      "metadata": {
        "id": "rR5Gwrd4b7K_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. **Creating DataFrame with Explicit Schema**:\n"
      ],
      "metadata": {
        "id": "25GvrGMcb-ap"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "schema = StructType([\n",
        "    StructField('name', StringType(), True),\n",
        "    StructField('properties', MapType(StringType(), StringType()), True)\n",
        "])\n",
        "\n",
        "df2 = spark.createDataFrame(data=dataDictionary, schema=schema)\n",
        "df2.printSchema()\n",
        "df2.show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aCLc_J-0cAnm",
        "outputId": "4502fa1f-d47d-48d5-8140-16492a539955"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- name: string (nullable = true)\n",
            " |-- properties: map (nullable = true)\n",
            " |    |-- key: string\n",
            " |    |-- value: string (valueContainsNull = true)\n",
            "\n",
            "+----------+-----------------------------+\n",
            "|name      |properties                   |\n",
            "+----------+-----------------------------+\n",
            "|James     |{eye -> brown, hair -> black}|\n",
            "|Michael   |{eye -> NULL, hair -> brown} |\n",
            "|Robert    |{eye -> black, hair -> red}  |\n",
            "|Washington|{eye -> grey, hair -> grey}  |\n",
            "|Jefferson |{eye -> , hair -> brown}     |\n",
            "+----------+-----------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "   - Defines an explicit schema using `StructType`.\n",
        "   - Creates a DataFrame with the explicit schema.\n",
        "   - Prints the schema and shows the DataFrame content.\n"
      ],
      "metadata": {
        "id": "Wi-ym16ycCov"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5. **Converting RDD to DataFrame with Separate Columns**:\n"
      ],
      "metadata": {
        "id": "LUSeqC1ccDnz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df3 = df.rdd.map(lambda x: (x.name, x.properties[\"hair\"], x.properties[\"eye\"])) \\\n",
        "            .toDF([\"name\", \"hair\", \"eye\"])\n",
        "df3.printSchema()\n",
        "df3.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l6uwEGDicFOP",
        "outputId": "b7d96358-36b1-49da-cfde-68655f23c884"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- name: string (nullable = true)\n",
            " |-- hair: string (nullable = true)\n",
            " |-- eye: string (nullable = true)\n",
            "\n",
            "+----------+-----+-----+\n",
            "|      name| hair|  eye|\n",
            "+----------+-----+-----+\n",
            "|     James|black|brown|\n",
            "|   Michael|brown| NULL|\n",
            "|    Robert|  red|black|\n",
            "|Washington| grey| grey|\n",
            "| Jefferson|brown|     |\n",
            "+----------+-----+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Converts the DataFrame to an RDD and then maps each row to extract `name`, `hair`, and `eye`.\n",
        "- Converts the RDD back to a DataFrame with separate columns for `name`, `hair`, and `eye`.\n",
        "- Prints the schema and shows the new DataFrame content.\n"
      ],
      "metadata": {
        "id": "im-dCpJVcHOk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6. **Extracting Columns from Dictionary Using withColumn and getItem**:\n"
      ],
      "metadata": {
        "id": "qKzoF3iFcJI8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.withColumn(\"hair\", df.properties.getItem(\"hair\")) \\\n",
        "  .withColumn(\"eye\", df.properties.getItem(\"eye\")) \\\n",
        "  .drop(\"properties\") \\\n",
        "  .show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "auP8Fb00cKr2",
        "outputId": "c725badd-5ce2-42f1-b494-27e95fc7d8e7"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+-----+-----+\n",
            "|      name| hair|  eye|\n",
            "+----------+-----+-----+\n",
            "|     James|black|brown|\n",
            "|   Michael|brown| NULL|\n",
            "|    Robert|  red|black|\n",
            "|Washington| grey| grey|\n",
            "| Jefferson|brown|     |\n",
            "+----------+-----+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Uses `withColumn` and `getItem` to create new columns `hair` and `eye` from the `properties` dictionary.\n",
        "- Drops the original `properties` column.\n",
        "- Shows the updated DataFrame content.\n"
      ],
      "metadata": {
        "id": "k_WQiu-NcMYU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7. **Extracting Columns from Dictionary Using withColumn and Direct Indexing**:\n"
      ],
      "metadata": {
        "id": "edGeZiMQcN2M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.withColumn(\"hair\", df.properties[\"hair\"]) \\\n",
        "  .withColumn(\"eye\", df.properties[\"eye\"]) \\\n",
        "  .drop(\"properties\") \\\n",
        "  .show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E4KWFQmDcPS0",
        "outputId": "d18a5f80-b65e-45fc-c950-c3f9ec090df9"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+-----+-----+\n",
            "|      name| hair|  eye|\n",
            "+----------+-----+-----+\n",
            "|     James|black|brown|\n",
            "|   Michael|brown| NULL|\n",
            "|    Robert|  red|black|\n",
            "|Washington| grey| grey|\n",
            "| Jefferson|brown|     |\n",
            "+----------+-----+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "   - Similar to the previous step, but uses direct indexing to extract `hair` and `eye` from the `properties` dictionary.\n",
        "   - Shows the updated DataFrame content.\n"
      ],
      "metadata": {
        "id": "U8aBZSlrcU8v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 8. **Extracting Keys from the Map and Creating Separate Columns**:\n"
      ],
      "metadata": {
        "id": "MjJNrDiNcV9Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "keysDF = df.select(explode(map_keys(df.properties))).distinct()\n",
        "keysList = keysDF.rdd.map(lambda x: x[0]).collect()\n",
        "keyCols = list(map(lambda x: col(\"properties\").getItem(x).alias(str(x)), keysList))\n",
        "df.select(df.name, *keyCols).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P27t8qyUcXbv",
        "outputId": "9ec66428-383b-4f20-8226-93a57adcf8b8"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+-----+-----+\n",
            "|      name|  eye| hair|\n",
            "+----------+-----+-----+\n",
            "|     James|brown|black|\n",
            "|   Michael| NULL|brown|\n",
            "|    Robert|black|  red|\n",
            "|Washington| grey| grey|\n",
            "| Jefferson|     |brown|\n",
            "+----------+-----+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Extracts the keys from the `properties` map using `map_keys` and `explode`.\n",
        "- Collects the distinct keys into a list.\n",
        "- Creates new columns for each key in the `properties` map using `getItem` and `alias`.\n",
        "- Selects the `name` column and the newly created columns, and shows the updated DataFrame content."
      ],
      "metadata": {
        "id": "pUdVpuftcZv7"
      }
    }
  ]
}