{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "TJKjcexez9Fq",
        "NH907I0izIDc",
        "5haC9pT5zRib",
        "X9Mb-LIgzaQH",
        "g2k8X3WazmXs"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 0. **Install PySpark**"
      ],
      "metadata": {
        "id": "TJKjcexez9Fq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyspark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fc51oRbw0MkQ",
        "outputId": "48740f74-d2ea-4574-c429-bb2f7886e89b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.10/dist-packages (3.5.1)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. **Initialize Spark session**:\n"
      ],
      "metadata": {
        "id": "NH907I0izIDc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.appName('SparkByExamples.com').getOrCreate()"
      ],
      "metadata": {
        "id": "OT7XKgqKzLzL"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "   - This initializes a Spark session with the application name 'SparkByExamples.com'. If a Spark session already exists, it will return the existing one; otherwise, it creates a new one.\n"
      ],
      "metadata": {
        "id": "OGdpAvWRzPS0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. **Import necessary functions**:\n"
      ],
      "metadata": {
        "id": "5haC9pT5zRib"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import col, expr"
      ],
      "metadata": {
        "id": "PZXR9U4NzT9N"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "   - Importing `col` and `expr` from `pyspark.sql.functions` to help with DataFrame column operations and SQL expressions.\n"
      ],
      "metadata": {
        "id": "nXHbTpUAzXUH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. **Define the data**:\n"
      ],
      "metadata": {
        "id": "X9Mb-LIgzaQH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = [(\"2019-01-23\", 1), (\"2019-06-24\", 2), (\"2019-09-20\", 3)]"
      ],
      "metadata": {
        "id": "I1U2zHSlzcgX"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "   - This is a list of tuples, where each tuple contains a date string and an increment value.\n"
      ],
      "metadata": {
        "id": "2mzhvthFzesN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. **Create a DataFrame from the data**:\n"
      ],
      "metadata": {
        "id": "h0Gjz31izgNH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = spark.createDataFrame(data).toDF(\"date\", \"increment\")"
      ],
      "metadata": {
        "id": "kYI3VHXOzihD"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sj0dBvzI1pYN",
        "outputId": "2fa10791-3fcb-4379-c74e-5fa32669b72e"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+---------+\n",
            "|      date|increment|\n",
            "+----------+---------+\n",
            "|2019-01-23|        1|\n",
            "|2019-06-24|        2|\n",
            "|2019-09-20|        3|\n",
            "+----------+---------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "   - This creates a Spark DataFrame from the list of tuples and assigns column names \"date\" and \"increment\".\n"
      ],
      "metadata": {
        "id": "dA4FAlyAzk0s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. **Perform the date manipulation and add a new column 'inc_date'**:\n"
      ],
      "metadata": {
        "id": "g2k8X3WazmXs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_with_inc_date = df.select(\n",
        "    col(\"date\"),\n",
        "    col(\"increment\"),\n",
        "    expr(\"add_months(to_date(date,'yyyy-MM-dd'), cast(increment as int))\").alias(\"inc_date\")\n",
        ")"
      ],
      "metadata": {
        "id": "WBvZ4M8Szqwr"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "   - `col(\"date\")` and `col(\"increment\")`: Selects the \"date\" and \"increment\" columns.\n",
        "   - `expr(\"add_months(to_date(date,'yyyy-MM-dd'), cast(increment as int))\")`:\n",
        "     - `to_date(date, 'yyyy-MM-dd')`: Converts the \"date\" string to a date object.\n",
        "     - `cast(increment as int)`: Casts the \"increment\" value to an integer.\n",
        "     - `add_months`: Adds the specified number of months to the date.\n",
        "     - `.alias(\"inc_date\")`: Assigns the result to a new column named \"inc_date\".\n"
      ],
      "metadata": {
        "id": "JJ2Q5Q8pzwJj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. **`expr()`**:\n",
        "   - **Purpose**: Allows you to use SQL expressions within the DataFrame API.\n",
        "   - **Usage**: `expr(\"SQL expression\")` enables you to write SQL syntax directly in your DataFrame transformations.\n",
        "\n",
        "2. **`to_date(date, 'yyyy-MM-dd')`**:\n",
        "   - **Purpose**: Converts a string column to a date column.\n",
        "   - **Details**:\n",
        "     - `date`: The column containing date strings.\n",
        "     - `'yyyy-MM-dd'`: The format of the date strings in the `date` column.\n",
        "   - **Result**: Converts the `date` string (e.g., '2019-01-23') to a date object of the format `yyyy-MM-dd`.\n",
        "\n",
        "3. **`cast(increment as int)`**:\n",
        "   - **Purpose**: Converts the `increment` column values to integers.\n",
        "   - **Details**:\n",
        "     - `increment`: The column containing numeric values that represent the number of months to add.\n",
        "   - **Result**: Ensures that the `increment` values are treated as integers for the next operation.\n",
        "\n",
        "4. **`add_months(to_date(date, 'yyyy-MM-dd'), cast(increment as int))`**:\n",
        "   - **Purpose**: Adds a specified number of months to a date.\n",
        "   - **Details**:\n",
        "     - `to_date(date, 'yyyy-MM-dd')`: The date to which months will be added.\n",
        "     - `cast(increment as int)`: The number of months to add, cast to an integer.\n",
        "   - **Result**: Produces a new date by adding the `increment` number of months to the `date` column.\n",
        "\n",
        "5. **`.alias(\"inc_date\")`**:\n",
        "   - **Purpose**: Assigns an alias (or name) to the resulting column from the expression.\n",
        "   - **Details**:\n",
        "     - `\"inc_date\"`: The name for the new column containing the resulting dates after the addition of months.\n",
        "   - **Result**: The resulting column will be named `inc_date`."
      ],
      "metadata": {
        "id": "1cSSO8tYIb9w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6. **Show the resulting DataFrame**:\n"
      ],
      "metadata": {
        "id": "Z6VcBRlAzyDt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_with_inc_date.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xKWB0lYqz0rt",
        "outputId": "91a0dfd4-6224-44fb-b23e-3eba647424e2"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+---------+----------+\n",
            "|      date|increment|  inc_date|\n",
            "+----------+---------+----------+\n",
            "|2019-01-23|        1|2019-02-23|\n",
            "|2019-06-24|        2|2019-08-24|\n",
            "|2019-09-20|        3|2019-12-20|\n",
            "+----------+---------+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "   - This displays the contents of the DataFrame, showing the original \"date\" and \"increment\" columns along with the new \"inc_date\" column.\n"
      ],
      "metadata": {
        "id": "djjwGuL6z2lB"
      }
    }
  ]
}