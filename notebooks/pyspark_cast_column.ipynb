{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 0. **Install PySpark**"
      ],
      "metadata": {
        "id": "TJKjcexez9Fq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyspark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fc51oRbw0MkQ",
        "outputId": "4943cad7-f1bd-4122-fbd4-ed61afa05e65"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.5.1.tar.gz (317.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.0/317.0 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.5.1-py2.py3-none-any.whl size=317488491 sha256=1c46b882e31fb009a5ff45ffd28367f2eea1cbe7d4d9c9b290ae367e008f9200\n",
            "  Stored in directory: /root/.cache/pip/wheels/80/1d/60/2c256ed38dddce2fdd93be545214a63e02fbd8d74fb0b7f3a6\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.5.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. **Importing Libraries and Initializing Spark Session**:\n"
      ],
      "metadata": {
        "id": "IF-Bus6mDRo3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pyspark\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession.builder.appName('SparkByExamples.com').getOrCreate()"
      ],
      "metadata": {
        "id": "WT1jRfLODS-c"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Imports necessary PySpark libraries.\n",
        "- Initializes a Spark session with the application name 'SparkByExamples.com'."
      ],
      "metadata": {
        "id": "LAT_P515DUhQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. **Defining Sample Data and Schema**:\n"
      ],
      "metadata": {
        "id": "-fOPzRwnDWQT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "simpleData = [(\"James\", 34, \"2006-01-01\", \"true\", \"M\", 3000.60),\n",
        "              (\"Michael\", 33, \"1980-01-10\", \"true\", \"F\", 3300.80),\n",
        "              (\"Robert\", 37, \"06-01-1992\", \"false\", \"M\", 5000.50)]\n",
        "\n",
        "columns = [\"firstname\", \"age\", \"jobStartDate\", \"isGraduated\", \"gender\", \"salary\"]\n",
        "df = spark.createDataFrame(data=simpleData, schema=columns)\n",
        "df.printSchema()\n",
        "df.show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zqrgjrF5DXzN",
        "outputId": "3c9e0b7d-897c-4e34-e6f2-e76f2475ce0f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- firstname: string (nullable = true)\n",
            " |-- age: long (nullable = true)\n",
            " |-- jobStartDate: string (nullable = true)\n",
            " |-- isGraduated: string (nullable = true)\n",
            " |-- gender: string (nullable = true)\n",
            " |-- salary: double (nullable = true)\n",
            "\n",
            "+---------+---+------------+-----------+------+------+\n",
            "|firstname|age|jobStartDate|isGraduated|gender|salary|\n",
            "+---------+---+------------+-----------+------+------+\n",
            "|James    |34 |2006-01-01  |true       |M     |3000.6|\n",
            "|Michael  |33 |1980-01-10  |true       |F     |3300.8|\n",
            "|Robert   |37 |06-01-1992  |false      |M     |5000.5|\n",
            "+---------+---+------------+-----------+------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Defines sample data as a list of tuples, where each tuple represents a row in the DataFrame.\n",
        "- Defines a schema with six fields: `firstname`, `age`, `jobStartDate`, `isGraduated`, `gender`, and `salary`.\n",
        "- Creates a DataFrame from the sample data and schema.\n",
        "- Prints the schema of the DataFrame.\n",
        "- Displays the content of the DataFrame without truncating the output.\n"
      ],
      "metadata": {
        "id": "YQwr3PEeDZe2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. **Casting Columns to Different Types Using DataFrame API**:"
      ],
      "metadata": {
        "id": "u8Gsn5PdDbOf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import col\n",
        "from pyspark.sql.types import StringType, BooleanType, DateType\n",
        "\n",
        "df2 = df.withColumn(\"age\", col(\"age\").cast(StringType())) \\\n",
        "        .withColumn(\"isGraduated\", col(\"isGraduated\").cast(BooleanType())) \\\n",
        "        .withColumn(\"jobStartDate\", col(\"jobStartDate\").cast(DateType()))\n",
        "df2.printSchema()\n",
        "df2.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uFLdi_KSDd57",
        "outputId": "7dd0b0ac-c452-4409-ede7-751706101626"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- firstname: string (nullable = true)\n",
            " |-- age: string (nullable = true)\n",
            " |-- jobStartDate: date (nullable = true)\n",
            " |-- isGraduated: boolean (nullable = true)\n",
            " |-- gender: string (nullable = true)\n",
            " |-- salary: double (nullable = true)\n",
            "\n",
            "+---------+---+------------+-----------+------+------+\n",
            "|firstname|age|jobStartDate|isGraduated|gender|salary|\n",
            "+---------+---+------------+-----------+------+------+\n",
            "|    James| 34|  2006-01-01|       true|     M|3000.6|\n",
            "|  Michael| 33|  1980-01-10|       true|     F|3300.8|\n",
            "|   Robert| 37|        NULL|      false|     M|5000.5|\n",
            "+---------+---+------------+-----------+------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Imports necessary functions and data types from `pyspark.sql.functions` and `pyspark.sql.types`.\n",
        "- Uses `withColumn` to cast the `age` column to `StringType`, `isGraduated` column to `BooleanType`, and `jobStartDate` column to `DateType`.\n",
        "- Prints the schema of the resulting DataFrame `df2`.\n"
      ],
      "metadata": {
        "id": "edJBthD7Dfuq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. **Casting Columns to Different Types Using `selectExpr`**:\n"
      ],
      "metadata": {
        "id": "VNLVV70bDhWi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df3 = df2.selectExpr(\"cast(age as int) age\",\n",
        "                    \"cast(isGraduated as string) isGraduated\",\n",
        "                    \"cast(jobStartDate as string) jobStartDate\")\n",
        "df3.printSchema()\n",
        "df3.show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EKcI0XfjDlDz",
        "outputId": "a71f4ccb-f780-4268-ac18-5631ef71f004"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- age: integer (nullable = true)\n",
            " |-- isGraduated: string (nullable = true)\n",
            " |-- jobStartDate: string (nullable = true)\n",
            "\n",
            "+---+-----------+------------+\n",
            "|age|isGraduated|jobStartDate|\n",
            "+---+-----------+------------+\n",
            "|34 |true       |2006-01-01  |\n",
            "|33 |true       |1980-01-10  |\n",
            "|37 |false      |NULL        |\n",
            "+---+-----------+------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Uses `selectExpr` to cast the `age` column to `int`, `isGraduated` column to `string`, and `jobStartDate` column to `string`.\n",
        "- Prints the schema and displays the content of the resulting DataFrame `df3`."
      ],
      "metadata": {
        "id": "UduWdPpZDmkq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. **Using SQL Queries to Perform Casting**:\n"
      ],
      "metadata": {
        "id": "7CyRDbmFDoA7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df3.createOrReplaceTempView(\"CastExample\")\n",
        "\n",
        "df4 = spark.sql(\"SELECT STRING(age), BOOLEAN(isGraduated), DATE(jobStartDate) from CastExample\")\n",
        "df4.printSchema()\n",
        "df4.show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RPEkkruQDpwf",
        "outputId": "61f7df74-3c20-425b-b71e-ccb8b2f6d96d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- age: string (nullable = true)\n",
            " |-- isGraduated: boolean (nullable = true)\n",
            " |-- jobStartDate: date (nullable = true)\n",
            "\n",
            "+---+-----------+------------+\n",
            "|age|isGraduated|jobStartDate|\n",
            "+---+-----------+------------+\n",
            "|34 |true       |2006-01-01  |\n",
            "|33 |true       |1980-01-10  |\n",
            "|37 |false      |NULL        |\n",
            "+---+-----------+------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Creates a temporary view `CastExample` from the DataFrame `df3`.\n",
        "- Uses a SQL query to cast the `age` column to `STRING`, `isGraduated` column to `BOOLEAN`, and `jobStartDate` column to `DATE`.\n",
        "- Prints the schema and displays the content of the resulting DataFrame `df4`."
      ],
      "metadata": {
        "id": "OtAKXL5iDrVM"
      }
    }
  ]
}